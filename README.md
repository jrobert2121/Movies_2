# Movies ETL

## Project Overview
To prepare for an upcoming hackathon, data must be extracted from Wikipedia and Kaggle, the datasets must then be transformed through data clean up and joining them together, and finally the cleaned dataset needs to be loaded to a SQL database.  This will provide hackathon participants with a clean dataset to use in their analysis.

## Purpose
In order to create an automated pipeline for intake of new data daily, one function is to be created that takes in three files and performs the extract, transform, and load process by adding the data into a PostgreSQL database.

## Resources
- Software:
  - Python version 3.7.10
  - Jupyter Notebook 6.3.0
  - PostgreSQL version 11
  - PgAdmin 4 version 5.7
- Datasources:
  - wikipedia-movies.json
  - movies_metadata.csv and ratings.csv from Kaggle's MovieLens dataset



